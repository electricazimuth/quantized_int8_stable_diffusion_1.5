# Why batch size 2?

Stable Diffusion's UNet processes the conditional and unconditional embeddings **concurrently**, not sequentially.  

1. **Embedding Generation:**
    *   **Conditional Embedding (c):** This comes from your text prompt (or other conditioning mechanisms). It's processed through a text encoder (like CLIP's text encoder) to create a context vector.
    *   **Unconditional Embedding (uc):** This is typically a "null" or empty embedding, representing the absence of a specific condition. It's often generated by processing an empty string or a placeholder token through the same text encoder.

2. **Concatenation:** The unconditional and conditional embeddings are concatenated together along the batch dimension.
    * For example if your original prompt was "A cat on a mat" and your null prompt was "" then your input to the unet model would be the embedding for ["", "A cat on a mat"]

3. **UNet Input:** The concatenated embeddings are fed into the UNet alongside the noisy latent image and the timestep embedding.

4. **Classifier-Free Guidance (CFG):** The magic happens during the sampling process. The UNet makes predictions based on both the conditional and unconditional embeddings simultaneously. During inference, these predictions are combined using the CFG scale parameter:
    *   `noise_pred = noise_pred_uncond + guidance_scale * (noise_pred_cond - noise_pred_uncond)`
    *   `noise_pred_uncond`: Prediction from the unconditional embedding.
    *   `noise_pred_cond`: Prediction from the conditional embedding.
    *   `guidance_scale`: A hyperparameter (typically between 7 and 11) that controls the strength of the conditioning. A higher scale means the model adheres more strongly to the prompt.

**Batch Size Implications for Static Shapes**

If you're setting a static shape for the UNet, you need to consider how the conditional and unconditional embeddings are handled.

*   **Original Stable Diffusion 1.5:** The original implementation inherently expects a batch size of 2 (or multiples of 2) because it processes the unconditional and conditional embeddings together as explained above.

*   **Your Static Shape:** If you want to maintain the original CFG behavior, **set the batch size to 2**. This will allow you to feed in the concatenated unconditional and conditional embeddings just like the original model.

**Why Not Batch Size 1?**

If you set the batch size to 1 and only provide the conditional embedding, you're essentially disabling classifier-free guidance. You'll still get an output, but it won't have the benefit of being steered away from the unconditional distribution, potentially leading to lower quality or less prompt-adherent results. You will also have to change how you perform inference as the equation `noise_pred = noise_pred_uncond + guidance_scale * (noise_pred_cond - noise_pred_uncond)` will no longer apply.

-   Stable Diffusion's UNet processes conditional and unconditional embeddings concurrently by concatenating them.
-   For static shapes and to maintain the intended CFG behavior, set your batch size to 2 to accommodate both embeddings, mirroring the original implementation.
-   Using a batch size of 1 effectively disables CFG unless you change your inference code as well.

#### Noisy Latent Input:
    *   (2, 4, 64, 64)
    *   `2`: Batch size (unconditional + conditional)
    *   `4`: Number of channels in the latent space
    *   `64`: Height
    *   `64`: Width
#### Timestep Embedding: 
    * (2, 320)
    * `2`: Batch size (unconditional + conditional)
    * `320`: Timestep embedding dimension
#### Text Embeddings (Context):
    *  (2, 77, 768)
    *   `2`: Batch size (unconditional + conditional)
    *   `77`: Sequence length
    *   `768`: CLIP text embedding dimension
